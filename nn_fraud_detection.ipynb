{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce56af1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import datetime\n",
    "import os, sys\n",
    "\n",
    "\n",
    "from matplotlib.pyplot import imshow, imsave\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63da9bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'fraudClassifier'\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b28b51cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 33]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"transaction_dataset.csv\")\n",
    "\n",
    "#Rename columns for easier access\n",
    "df.columns = df.columns.str.strip().str.replace(' ','_').str.lower()\n",
    "\n",
    "#Remove weird stuff \n",
    "df.drop(columns=['unnamed:_0'], inplace=True)\n",
    "\n",
    "#Remove duplicate accounts\n",
    "df.drop_duplicates(subset=['address'], inplace=True)\n",
    "\n",
    "#Remove accounts \n",
    "df.drop(columns=['address'], inplace=True)\n",
    "\n",
    "#Remove index\n",
    "df.drop(columns=['index'], inplace=True)\n",
    "\n",
    "#Remove token names \n",
    "df.drop(columns=['erc20_most_sent_token_type','erc20_most_rec_token_type'], inplace = True)\n",
    "\n",
    "#Remove var=0 columns\n",
    "df.drop(df.var(numeric_only=True)[df.var(numeric_only=True) == 0].index, axis = 1, inplace = True)\n",
    "\n",
    "#Remove small distribution columns\n",
    "small_distr_col = []\n",
    "for col in df.columns[3:] :\n",
    "    if len(df[col].value_counts()) < 10:\n",
    "        small_distr_col.append(col)\n",
    "df.drop(columns=small_distr_col,inplace = True)\n",
    "\n",
    "\n",
    "#Replace nan values by median \n",
    "df.fillna(df.median(numeric_only=True), inplace=True)\n",
    "# Remove negative values \n",
    "df[df<0] = None \n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df_n = df.copy()\n",
    "\n",
    "#Normalization \n",
    "for col in df_n.columns[1:]:\n",
    "    df_n[col] = (df_n[col]-df_n[col].mean())/df_n[col].std()\n",
    "means = [df[col].mean() for col in df.columns[1:]]\n",
    "stds = [df[col].std() for col in df.columns[1:]]\n",
    "\n",
    "\n",
    "class Accounts(torch.utils.data.Dataset):\n",
    "    def __init__(self,df):\n",
    "\n",
    "        x=df.iloc[:,1:].values\n",
    "        y=df.iloc[:,0].values\n",
    "\n",
    "        self.x_train=torch.tensor(x,dtype=torch.float32)\n",
    "        self.y_train=torch.tensor(y,dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y_train)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x_train[idx],self.y_train[idx]\n",
    "\n",
    "    \n",
    "dataset = Accounts(df_n)\n",
    "batch_size = 64\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "features_size= 33\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler,drop_last=True)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                sampler=valid_sampler,drop_last=True)\n",
    "\n",
    "for i, (data, labels) in enumerate(train_loader):\n",
    "    print(data.shape, labels.shape)\n",
    "    break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4546f6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onehot(x, num_classes=2):\n",
    "    assert isinstance(x, int) or isinstance(x, (torch.LongTensor, torch.cuda.LongTensor))\n",
    "    if isinstance(x, int):\n",
    "        c = torch.zeros(1, num_classes).long()\n",
    "        c[0][x] = 1\n",
    "    else:\n",
    "        x = x.cpu()\n",
    "        c = torch.LongTensor(x.size(0), num_classes)\n",
    "        c.zero_()\n",
    "        c.scatter_(1, x, 1) # dim, index, src value\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66965081",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "        Simple Discriminator w/ MLP\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=features_size, num_classes=1):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(input_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, num_classes),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        y_ = self.layer(x)\n",
    "        return y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "327a235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b07d1629",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "model_opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "max_epoch = 100\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c08c61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate(data = validation_loader):\n",
    "    model.eval()  # Important: eval mode (affects dropout, batch norm etc)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for address, labels in data:\n",
    "        x,y = address.to(DEVICE), labels.to(DEVICE)\n",
    "        output = model(x)\n",
    "        test_loss += criterion(output, y.view(batch_size,1).float()).item() * len(address)\n",
    "        pred = output.round()\n",
    "        correct+= pred.eq(labels.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(validation_loader.dataset)\n",
    "    correct/=len(validation_loader.dataset)\n",
    "    return test_loss, correct*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dd33568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/100, Step: 0, Train Loss: 0.6616, Test Loss: 0.126, Accuracy: 14.9%\n",
      "Epoch: 9/100, Step: 1000, Train Loss: 0.05724, Test Loss: 0.03473, Accuracy: 18.83%\n",
      "Epoch: 18/100, Step: 2000, Train Loss: 0.07023, Test Loss: 0.02483, Accuracy: 18.72%\n",
      "Epoch: 27/100, Step: 3000, Train Loss: 0.05631, Test Loss: 0.01675, Accuracy: 18.88%\n",
      "Epoch: 36/100, Step: 4000, Train Loss: 0.03492, Test Loss: 0.02601, Accuracy: 18.86%\n",
      "Epoch: 45/100, Step: 5000, Train Loss: 0.02531, Test Loss: 0.01876, Accuracy: 19%\n",
      "Epoch: 54/100, Step: 6000, Train Loss: 0.02349, Test Loss: 0.02115, Accuracy: 18.89%\n",
      "Epoch: 63/100, Step: 7000, Train Loss: 0.02078, Test Loss: 0.02274, Accuracy: 18.88%\n",
      "Epoch: 72/100, Step: 8000, Train Loss: 0.05295, Test Loss: 0.02206, Accuracy: 18.81%\n",
      "Epoch: 81/100, Step: 9000, Train Loss: 0.003935, Test Loss: 0.03495, Accuracy: 18.88%\n",
      "Epoch: 90/100, Step: 10000, Train Loss: 0.04135, Test Loss: 0.02445, Accuracy: 18.98%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epoch):\n",
    "    for idx, (address, labels) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        # Training Discriminator\n",
    "        x,y = address.to(DEVICE), labels.to(DEVICE)\n",
    "        output = model(x)\n",
    "        loss = criterion(output,y.view(batch_size,1).float())\n",
    "        \n",
    "        model_opt.zero_grad()\n",
    "        loss.backward()\n",
    "        model_opt.step()\n",
    "        \n",
    "        test_loss,acc = validate(validation_loader)\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print('Epoch: {}/{}, Step: {}, Train Loss: {:.4g}, Test Loss: {:.4g}, Accuracy: {:.4g}%'.format(epoch, max_epoch, step, loss.item(),test_loss,acc))\n",
    "    \n",
    "        step += 1\n",
    "torch.save(model.state_dict(), \"./models/fraud_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9f3f1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13618,)\n"
     ]
    }
   ],
   "source": [
    "oversample = SMOTE()\n",
    "X_train, y_train = oversample.fit_resample(df_n.iloc[:,1:].values,df_n.iloc[:,0].values)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a08c010f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 33]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "class AccountsAug(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "\n",
    "        x=X_train\n",
    "        y=y_train\n",
    "\n",
    "        self.x_train=torch.tensor(x,dtype=torch.float32)\n",
    "        self.y_train=torch.tensor(y,dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y_train)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x_train[idx],self.y_train[idx]\n",
    "dataset = AccountsAug()\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "aug_train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler,drop_last=True)\n",
    "aug_validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                sampler=valid_sampler,drop_last=True)\n",
    "\n",
    "for i, (data, labels) in enumerate(aug_train_loader):\n",
    "    print(data.shape, labels.shape)\n",
    "    break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f56ffa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/100, Step: 0, Train Loss: 0.6909, Test Loss: 0.2108, Accuracy: 15.23%\n",
      "Epoch: 5/100, Step: 1000, Train Loss: 0.6941, Test Loss: 0.2108, Accuracy: 15.17%\n",
      "Epoch: 11/100, Step: 2000, Train Loss: 0.6979, Test Loss: 0.2108, Accuracy: 15.17%\n",
      "Epoch: 17/100, Step: 3000, Train Loss: 0.6882, Test Loss: 0.2108, Accuracy: 15.14%\n",
      "Epoch: 23/100, Step: 4000, Train Loss: 0.6908, Test Loss: 0.2108, Accuracy: 15.16%\n",
      "Epoch: 29/100, Step: 5000, Train Loss: 0.6949, Test Loss: 0.2108, Accuracy: 15.12%\n",
      "Epoch: 35/100, Step: 6000, Train Loss: 0.6892, Test Loss: 0.2108, Accuracy: 15.19%\n",
      "Epoch: 41/100, Step: 7000, Train Loss: 0.7009, Test Loss: 0.2108, Accuracy: 15.16%\n",
      "Epoch: 47/100, Step: 8000, Train Loss: 0.6903, Test Loss: 0.2108, Accuracy: 15.19%\n",
      "Epoch: 52/100, Step: 9000, Train Loss: 0.689, Test Loss: 0.2108, Accuracy: 15.15%\n",
      "Epoch: 58/100, Step: 10000, Train Loss: 0.6906, Test Loss: 0.2108, Accuracy: 15.11%\n",
      "Epoch: 64/100, Step: 11000, Train Loss: 0.6944, Test Loss: 0.2108, Accuracy: 15.19%\n",
      "Epoch: 70/100, Step: 12000, Train Loss: 0.6922, Test Loss: 0.2108, Accuracy: 15.17%\n",
      "Epoch: 76/100, Step: 13000, Train Loss: 0.6873, Test Loss: 0.2108, Accuracy: 15.23%\n",
      "Epoch: 82/100, Step: 14000, Train Loss: 0.6992, Test Loss: 0.2108, Accuracy: 15.19%\n",
      "Epoch: 88/100, Step: 15000, Train Loss: 0.6899, Test Loss: 0.2108, Accuracy: 15.16%\n",
      "Epoch: 94/100, Step: 16000, Train Loss: 0.6972, Test Loss: 0.2108, Accuracy: 15.19%\n"
     ]
    }
   ],
   "source": [
    "model = Classifier()\n",
    "step = 0\n",
    "for epoch in range(max_epoch):\n",
    "    for idx, (address, labels) in enumerate(aug_train_loader):\n",
    "        model.train()\n",
    "        # Training Discriminator\n",
    "        x,y = address.to(DEVICE), labels.to(DEVICE)\n",
    "        output = model(x)\n",
    "        loss = criterion(output,y.view(batch_size,1).float())\n",
    "        \n",
    "        model_opt.zero_grad()\n",
    "        loss.backward()\n",
    "        model_opt.step()\n",
    "        \n",
    "        test_loss,acc = validate(aug_validation_loader)\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print('Epoch: {}/{}, Step: {}, Train Loss: {:.4g}, Test Loss: {:.4g}, Accuracy: {:.4g}%'.format(epoch, max_epoch, step, loss.item(),test_loss,acc))\n",
    "    \n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac83376e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
