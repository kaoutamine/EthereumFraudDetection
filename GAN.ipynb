{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe26e08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import datetime\n",
    "import os, sys\n",
    "\n",
    "from matplotlib.pyplot import imshow, imsave\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aef4ee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'ConditionalGAN'\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76ae8dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 33]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"transaction_dataset.csv\")\n",
    "\n",
    "#Rename columns for easier access\n",
    "df.columns = df.columns.str.strip().str.replace(' ','_').str.lower()\n",
    "\n",
    "#Remove weird stuff \n",
    "df.drop(columns=['unnamed:_0'], inplace=True)\n",
    "\n",
    "#Remove duplicate accounts\n",
    "df.drop_duplicates(subset=['address'], inplace=True)\n",
    "\n",
    "#Remove accounts \n",
    "df.drop(columns=['address'], inplace=True)\n",
    "\n",
    "#Remove index\n",
    "df.drop(columns=['index'], inplace=True)\n",
    "\n",
    "#Remove token names \n",
    "df.drop(columns=['erc20_most_sent_token_type','erc20_most_rec_token_type'], inplace = True)\n",
    "\n",
    "#Remove var=0 columns\n",
    "df.drop(df.var(numeric_only=True)[df.var(numeric_only=True) == 0].index, axis = 1, inplace = True)\n",
    "\n",
    "#Remove small distribution columns\n",
    "small_distr_col = []\n",
    "for col in df.columns[3:] :\n",
    "    if len(df[col].value_counts()) < 10:\n",
    "        small_distr_col.append(col)\n",
    "df.drop(columns=small_distr_col,inplace = True)\n",
    "\n",
    "\n",
    "#Replace nan values by median \n",
    "df.fillna(df.median(numeric_only=True), inplace=True)\n",
    "# Remove negative values \n",
    "df[df<0] = None \n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df_n = df.copy()\n",
    "\n",
    "#Normalization \n",
    "for col in df_n.columns[1:]:\n",
    "    df_n[col] = (df_n[col]-df_n[col].mean())/df_n[col].std()\n",
    "means = [df[col].mean() for col in df.columns[1:]]\n",
    "stds = [df[col].std() for col in df.columns[1:]]\n",
    "\n",
    "for i in range(len(df.values)):\n",
    "    if(not np.allclose(df_n.values[i][1:] * stds + means, df.values[i][1:])):\n",
    "        print(\"ay caramba\")\n",
    "\n",
    "class Accounts(torch.utils.data.Dataset):\n",
    "    def __init__(self,df):\n",
    "\n",
    "        x=df.iloc[:,1:].values\n",
    "        y=df.iloc[:,0].values\n",
    "\n",
    "        self.x_train=torch.tensor(x,dtype=torch.float32)\n",
    "        self.y_train=torch.tensor(y,dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y_train)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x_train[idx],self.y_train[idx]\n",
    "\n",
    "batch_size = 64\n",
    "features_size = 33 \n",
    "cond_size = 2 # Fraud, No Fraud\n",
    "n_noise = 50\n",
    "data_loader = DataLoader(dataset=Accounts(df_n), batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "sample_data = None \n",
    "for i, (data, labels) in enumerate(data_loader):\n",
    "    print(data.shape, labels.shape)\n",
    "    sample_data = data[0], labels[0]\n",
    "    break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddd6d17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onehot(x, num_classes=cond_size):\n",
    "    assert isinstance(x, int) or isinstance(x, (torch.LongTensor, torch.cuda.LongTensor))\n",
    "    if isinstance(x, int):\n",
    "        c = torch.zeros(1, num_classes).long()\n",
    "        c[0][x] = 1\n",
    "    else:\n",
    "        x = x.cpu()\n",
    "        c = torch.LongTensor(x.size(0), num_classes)\n",
    "        c.zero_()\n",
    "        c.scatter_(1, x, 1) # dim, index, src value\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1b2e748",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "        Simple Discriminator w/ MLP\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=features_size, condition_size=cond_size, num_classes=1):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(input_size+condition_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, num_classes),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, c):        \n",
    "        x, c = x.view(x.size(0), -1), c.view(c.size(0), -1).float()\n",
    "        v = torch.cat((x, c), 1) # v: [input, label] concatenated vector\n",
    "        y_ = self.layer(v)\n",
    "        return y_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb052c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "        Simple Generator w/ MLP\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=n_noise, condition_size=cond_size, num_classes=features_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(input_size+condition_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, c):\n",
    "        x, c = x.view(x.size(0), -1), c.view(c.size(0), -1).float()\n",
    "        v = torch.cat((x, c), 1) # v: [input, label] concatenated vector\n",
    "        y_ = self.layer(v)\n",
    "        y_ = y_.view(x.size(0), 1, 33)\n",
    "        return y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "682769ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator().to(DEVICE)\n",
    "G = Generator().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c036b677",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "D_opt = torch.optim.Adam(D.parameters(), lr=0.0001)\n",
    "G_opt = torch.optim.Adam(G.parameters(), lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3dfbc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 1000 # need more than 100 epochs for training generator\n",
    "step = 0\n",
    "n_critic = 1 # for training more k steps about Discriminator\n",
    "\n",
    "\n",
    "D_labels = torch.ones([batch_size, 1]).to(DEVICE) # Discriminator Label to real\n",
    "D_fakes = torch.zeros([batch_size, 1]).to(DEVICE) # Discriminator Label to fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65e87e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1000, Step: 0, D Loss: 1.388810157775879, G Loss: 0.6392515897750854\n",
      "Epoch: 21/1000, Step: 3000, D Loss: 0.9176537990570068, G Loss: 1.1638981103897095\n",
      "Epoch: 43/1000, Step: 6000, D Loss: 1.148071527481079, G Loss: 0.8979008197784424\n",
      "Epoch: 65/1000, Step: 9000, D Loss: 1.1744483709335327, G Loss: 0.9083535671234131\n",
      "Epoch: 86/1000, Step: 12000, D Loss: 1.1933451890945435, G Loss: 0.8847957253456116\n",
      "Epoch: 108/1000, Step: 15000, D Loss: 1.1478500366210938, G Loss: 1.0138728618621826\n",
      "Epoch: 130/1000, Step: 18000, D Loss: 1.0995596647262573, G Loss: 0.8989588022232056\n",
      "Epoch: 152/1000, Step: 21000, D Loss: 1.2822014093399048, G Loss: 1.1171172857284546\n",
      "Epoch: 173/1000, Step: 24000, D Loss: 1.0979729890823364, G Loss: 0.9130597710609436\n",
      "Epoch: 195/1000, Step: 27000, D Loss: 1.1252436637878418, G Loss: 0.9190374612808228\n",
      "Epoch: 217/1000, Step: 30000, D Loss: 1.170263648033142, G Loss: 0.8610841631889343\n",
      "Epoch: 239/1000, Step: 33000, D Loss: 1.1808593273162842, G Loss: 0.8536449074745178\n",
      "Epoch: 260/1000, Step: 36000, D Loss: 1.1668169498443604, G Loss: 0.8686120510101318\n",
      "Epoch: 282/1000, Step: 39000, D Loss: 1.2868434190750122, G Loss: 0.9069339036941528\n",
      "Epoch: 304/1000, Step: 42000, D Loss: 1.1299995183944702, G Loss: 0.9685218334197998\n",
      "Epoch: 326/1000, Step: 45000, D Loss: 1.1448770761489868, G Loss: 0.8431416749954224\n",
      "Epoch: 347/1000, Step: 48000, D Loss: 1.1919434070587158, G Loss: 0.95304936170578\n",
      "Epoch: 369/1000, Step: 51000, D Loss: 1.0505452156066895, G Loss: 0.79323810338974\n",
      "Epoch: 391/1000, Step: 54000, D Loss: 1.2520098686218262, G Loss: 0.8143556118011475\n",
      "Epoch: 413/1000, Step: 57000, D Loss: 1.0925668478012085, G Loss: 0.8724860548973083\n",
      "Epoch: 434/1000, Step: 60000, D Loss: 1.1894009113311768, G Loss: 0.8702967166900635\n",
      "Epoch: 456/1000, Step: 63000, D Loss: 1.2228271961212158, G Loss: 0.8926563858985901\n",
      "Epoch: 478/1000, Step: 66000, D Loss: 1.1473517417907715, G Loss: 0.8944658637046814\n",
      "Epoch: 500/1000, Step: 69000, D Loss: 1.1765894889831543, G Loss: 0.8739861845970154\n",
      "Epoch: 521/1000, Step: 72000, D Loss: 1.1229586601257324, G Loss: 0.8850049376487732\n",
      "Epoch: 543/1000, Step: 75000, D Loss: 1.1407688856124878, G Loss: 0.8772823810577393\n",
      "Epoch: 565/1000, Step: 78000, D Loss: 1.1332342624664307, G Loss: 0.8962308764457703\n",
      "Epoch: 586/1000, Step: 81000, D Loss: 1.203995943069458, G Loss: 0.8556885719299316\n",
      "Epoch: 608/1000, Step: 84000, D Loss: 1.1732580661773682, G Loss: 0.8784594535827637\n",
      "Epoch: 630/1000, Step: 87000, D Loss: 1.1349494457244873, G Loss: 0.8574987649917603\n",
      "Epoch: 652/1000, Step: 90000, D Loss: 1.1721467971801758, G Loss: 0.8515180349349976\n",
      "Epoch: 673/1000, Step: 93000, D Loss: 1.170333981513977, G Loss: 0.9135189652442932\n",
      "Epoch: 695/1000, Step: 96000, D Loss: 1.1860544681549072, G Loss: 0.9925433993339539\n",
      "Epoch: 717/1000, Step: 99000, D Loss: 1.243194580078125, G Loss: 0.8700518012046814\n",
      "Epoch: 739/1000, Step: 102000, D Loss: 1.1319730281829834, G Loss: 0.8579912781715393\n",
      "Epoch: 760/1000, Step: 105000, D Loss: 1.0946100950241089, G Loss: 0.9571793675422668\n",
      "Epoch: 782/1000, Step: 108000, D Loss: 1.2877486944198608, G Loss: 0.8399226665496826\n",
      "Epoch: 804/1000, Step: 111000, D Loss: 1.1920901536941528, G Loss: 0.9073476791381836\n",
      "Epoch: 826/1000, Step: 114000, D Loss: 1.2193602323532104, G Loss: 0.9239352941513062\n",
      "Epoch: 847/1000, Step: 117000, D Loss: 1.1162707805633545, G Loss: 0.9667089581489563\n",
      "Epoch: 869/1000, Step: 120000, D Loss: 1.1897459030151367, G Loss: 0.8566487431526184\n",
      "Epoch: 891/1000, Step: 123000, D Loss: 1.0794141292572021, G Loss: 0.9256347417831421\n",
      "Epoch: 913/1000, Step: 126000, D Loss: 1.0798840522766113, G Loss: 0.8300747275352478\n",
      "Epoch: 934/1000, Step: 129000, D Loss: 1.130009412765503, G Loss: 0.8961901068687439\n",
      "Epoch: 956/1000, Step: 132000, D Loss: 1.2113075256347656, G Loss: 0.8542859554290771\n",
      "Epoch: 978/1000, Step: 135000, D Loss: 1.1289829015731812, G Loss: 0.9195642471313477\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epoch):\n",
    "    for idx, (address, labels) in enumerate(data_loader):\n",
    "        # Training Discriminator\n",
    "        x = address.to(DEVICE)\n",
    "        y = labels.view(batch_size, 1)\n",
    "        y = to_onehot(y).to(DEVICE)\n",
    "        x_outputs = D(x, y)\n",
    "        D_x_loss = criterion(x_outputs, D_labels)\n",
    "\n",
    "        z = torch.randn(batch_size, n_noise).to(DEVICE)\n",
    "        z_outputs = D(G(z, y), y)\n",
    "        D_z_loss = criterion(z_outputs, D_fakes)\n",
    "        D_loss = D_x_loss + D_z_loss\n",
    "        \n",
    "        D.zero_grad()\n",
    "        D_loss.backward()\n",
    "        D_opt.step()\n",
    "        \n",
    "        if step % n_critic == 0:\n",
    "            # Training Generator\n",
    "            z = torch.randn(batch_size, n_noise).to(DEVICE)\n",
    "            z_outputs = D(G(z, y), y)\n",
    "            G_loss = criterion(z_outputs, D_labels)\n",
    "\n",
    "            G.zero_grad()\n",
    "            G_loss.backward()\n",
    "            G_opt.step()\n",
    "        \n",
    "        if step % 3000 == 0:\n",
    "            print('Epoch: {}/{}, Step: {}, D Loss: {}, G Loss: {}'.format(epoch, max_epoch, step, D_loss.item(), G_loss.item()))\n",
    "        \n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e7e703d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(D.state_dict(), \"./models/gan_discriminator\")\n",
    "torch.save(G.state_dict(), \"./models/gan_generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49fa3ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = Discriminator()\n",
    "G = Generator()\n",
    "D.load_state_dict(torch.load(\"./models/gan_discriminator\"))\n",
    "G.load_state_dict(torch.load(\"./models/gan_generator\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b514362",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.eval()\n",
    "z = torch.randn(batch_size, n_noise).to(DEVICE)\n",
    "y = torch.ones(batch_size,dtype=torch.long)\n",
    "y = to_onehot(y.view(batch_size, 1)).to(DEVICE)\n",
    "acc = G(z, y)[0][0].detach().numpy()\n",
    "acc = means * acc + means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "105783ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATED vs MEAN\n",
      "avg_min_between_sent_tnx : 5948.47957125412 --- 4751.08584728507\n",
      "avg_min_between_received_tnx : 5995.175379787375 --- 7725.355837104092\n",
      "time_diff_between_first_and_last_(mins) : 118414.16819466832 --- 184074.94802488675\n",
      "sent_tnx : 73.7200436267985 --- 83.40972850678733\n",
      "received_tnx : 132.35999240744775 --- 161.8118778280543\n",
      "number_of_created_contracts : 3.1700916041596896 --- 3.271606334841629\n",
      "unique_received_from_addresses : 27.383512701599845 --- 29.192760180995474\n",
      "unique_sent_to_addresses : 16.856384413149968 --- 17.65079185520362\n",
      "min_value_received : 42.52257075681511 --- 47.914248338122164\n",
      "max_value_received : 433.3165198459148 --- 455.56829526188045\n",
      "avg_val_received : 63.73291831641915 --- 75.89643693065601\n",
      "min_val_sent : 5.484540387598715 --- 5.168499833710412\n",
      "max_val_sent : 179.65870081008998 --- 192.80073998042965\n",
      "avg_val_sent : 41.01012841226796 --- 46.22433743585901\n",
      "total_transactions_(including_tnx_to_create_contract : 205.7736699541365 --- 248.49321266968326\n",
      "total_ether_sent : 7068.833775098119 --- 7251.667843627991\n",
      "total_ether_received : 11125.122175912311 --- 11648.083414247189\n",
      "total_ether_balance : 4360.84426563537 --- 4396.415569433398\n",
      "total_erc20_tnxs : 24.893948588213497 --- 26.31131221719457\n",
      "erc20_total_ether_received : 12961857.511738382 --- 13247527.254943527\n",
      "erc20_total_ether_sent : 13215146.386036828 --- 13391090.630984955\n",
      "erc20_total_ether_sent_contract : 110.80179244631995 --- 113.09775233787508\n",
      "erc20_uniq_sent_addr : 3.9816664291431967 --- 4.11052036199095\n",
      "erc20_uniq_rec_addr : 4.565853669322454 --- 4.718552036199095\n",
      "erc20_uniq_rec_contract_addr : 2.7795722293718064 --- 2.659841628959276\n",
      "erc20_min_val_rec : 409.9349624595975 --- 420.37171171662345\n",
      "erc20_max_val_rec : 10625624.057567928 --- 10934866.221363151\n",
      "erc20_avg_val_rec : 2368631.730507811 --- 2403711.9659335716\n",
      "erc20_min_val_sent : 11744.791211243988 --- 11837.371427616516\n",
      "erc20_max_val_sent : 12810387.207202686 --- 12947105.108254325\n",
      "erc20_avg_val_sent : 6354648.772061875 --- 6426962.37893045\n",
      "erc20_uniq_sent_token_name : 0.4014268755036242 --- 0.4647058823529412\n",
      "erc20_uniq_rec_token_name : 2.7924015900676404 --- 2.633257918552036\n"
     ]
    }
   ],
   "source": [
    "print(\"GENERATED vs MEAN\")\n",
    "for i,col in enumerate(df.columns[1:]):\n",
    "    print(col,end=\" : \")\n",
    "    print(acc[i],end=\" --- \")\n",
    "    print(means[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5304ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e701e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
